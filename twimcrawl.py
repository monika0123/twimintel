# -*- coding: utf-8 -*-
"""twimcrawl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13HsYCnpMwNg3MBbFNsFm8VCRGgD7V2tp
"""

import numpy as np
import pandas as pd
import requests
import bs4
import re

import lxml.etree as xml
from requests import get
from bs4 import BeautifulSoup
import flask
from flask import Flask, request, jsonify, render_template

#url=["https://medium.com/the-banking-scene/the-future-of-banking-8b2c313f502a","https://medium.com/@abhishekkothari/bracing-for-impact-5681e18be2d4"]
{
    "urls": [
         "https://medium.com/the-banking-scene/the-future-of-banking-8b2c313f502a"]
    
}


app=flask.Flask(__name__)
app.config["DEBUG"]=True
data=[]
@app.route("/", methods=['POST'])
def root():
	url= request.get_json()
	print(url)
	link = url['urls']
	for i in link:
	  r=requests.get(i)
	  r.encoding = 'utf-8'
	  html_content = r.text
	  html_soup = BeautifulSoup(html_content, 'html.parser')
	  type(html_soup)
	  para = html_soup.find_all('p',"")

	  for l in range(len(para)):
	    contest=html_tag_remover(str(para[l]))
	    query={
	            "Contents":contest,
	           }
	    data.append(query)

	dataframe=pd.DataFrame(data)
	dataframe=dataframe.dropna()
	dataframe.to_csv('crawl_datset.csv')
	return "success!"
	
def html_tag_remover(texts):

    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', texts)
    return cleantext


if __name__=="__main__":
	app.run(debug=True)